
"""
VASP åˆ†å­åŠ¨åŠ›å­¦æ™ºèƒ½åˆ†æå™¨ - åŸºäº PyMatGen çš„MDåˆ†æä¸å¯è§†åŒ–
åŠŸèƒ½æ¦‚è§ˆï¼ˆä¸ `dos_analyzer.py` é£æ ¼ä¸€è‡´ï¼‰ï¼š
- æ‰©æ•£æ€§è´¨åˆ†æï¼š
  - MSD è®¡ç®—ï¼ˆæŒ‰å…ƒç´ åˆ†ç±»ï¼‰
  - æ‰©æ•£ç³»æ•°è‡ªåŠ¨è®¡ç®—ï¼ˆçº¿æ€§æ‹Ÿåˆå°¾æ®µï¼‰
  - ç¦»å­ç”µå¯¼ç‡è®¡ç®—ï¼ˆNernstâ€“Einsteinï¼‰
  - Arrhenius å›¾ç”Ÿæˆï¼ˆå¤šæ¸©æ•°æ®è‡ªåŠ¨èšåˆï¼‰
  - æ¿€æ´»èƒ½è‡ªåŠ¨æ‹Ÿåˆï¼ˆln D vs 1/Tï¼‰
- å¾„å‘åˆ†å¸ƒå‡½æ•°ï¼ˆRDFï¼‰åˆ†æï¼š
  - å…¨ä½“/åˆ†å…ƒç´  RDF è®¡ç®—
  - é…ä½æ•°ç»Ÿè®¡ï¼ˆç§¯åˆ†è‡³é¦–æå°å€¼ï¼‰
  - å³°ä½è¯†åˆ«ä¸åˆ†æï¼ˆç®€æ˜“å³°å€¼æ£€æµ‹ï¼‰
  - ç»“æ„æ¼”åŒ–è¿½è¸ªï¼ˆé¦–å³°éšæ—¶é—´æ¼”åŒ–ï¼‰
  - ä¸å®éªŒ XRD/ä¸­å­æ•£å°„å¯¹æ¯”ï¼ˆæä¾›è¦†ç›–æ¥å£ï¼‰
- ç³»ç»Ÿç¨³å®šæ€§ç›‘æ§ï¼š
  - èƒ½é‡/æ¸©åº¦/å‹åŠ›æ¼”åŒ–
  - æ™¶æ ¼å‚æ•°å˜åŒ–è¿½è¸ªï¼ˆa, b, c, ä½“ç§¯ï¼‰
  - å¯†åº¦æ³¢åŠ¨åˆ†æ
  - å¹³è¡¡æ€è¯†åˆ«ï¼ˆæ»šåŠ¨æ–œç‡é˜ˆå€¼ï¼‰
  - å¼‚å¸¸çŠ¶æ€é¢„è­¦ï¼ˆç®€å•Zåˆ†æ•°é˜ˆå€¼ï¼‰

è¾“å…¥å»ºè®®ï¼šåŒ…å« XDATCARï¼ˆè½¨è¿¹ï¼‰ã€OUTCARï¼ˆçƒ­åŠ›å­¦ä¿¡æ¯ï¼‰ã€vasprun.xmlï¼ˆè¡¥å……ï¼‰ã€INCARï¼ˆæ­¥é•¿POTIMç­‰ï¼‰
è¾“å‡ºï¼šåœ¨å·¥ä½œç›®å½•ä¸‹ç”Ÿæˆ MD_output/ å›¾è¡¨ä¸æ•°æ®ï¼Œå¹¶ç”Ÿæˆ HTML æŠ¥å‘Šã€‚
"""

import os
import io
import json
import math
import base64
import logging
import importlib
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Iterable

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from datetime import datetime

# PyMatGen
from pymatgen.io.vasp import Outcar
from pymatgen.io.vasp.outputs import Xdatcar, Vasprun
from pymatgen.io.vasp.inputs import Incar
from pymatgen.core import Structure, Element
from pymatgen.analysis.diffraction.xrd import XRDCalculator

from pymatgen.analysis.diffusion.analyzer import DiffusionAnalyzer

try:
    # æŸäº›ç‰ˆæœ¬æä¾›ä¸­å­è¡å°„è®¡ç®—å™¨
    from pymatgen.analysis.diffraction.neutron import NDCalculator as NeutronDiffractionCalculator  # type: ignore
except Exception:  # pragma: no cover - å¯é€‰ä¾èµ–
    NeutronDiffractionCalculator = None

try:
    # pymatgençš„RDFåˆ†æå·¥å…·
    from pymatgen.analysis.diffusion.aimd.rdf import RadialDistributionFunction
except ImportError:
    try:
        # å¤‡ç”¨å¯¼å…¥è·¯å¾„
        from pymatgen.analysis.diffusion.rdf import RadialDistributionFunction  # type: ignore
    except ImportError:
        RadialDistributionFunction = None


# è‡ªå®šä¹‰çš„åŸºäºpymatgenæ ¸å¿ƒåŠŸèƒ½çš„RDFåˆ†æå™¨
class PyMatGenRDFAnalyzer:
    """åŸºäºPyMatGenæ ¸å¿ƒåŠŸèƒ½çš„RDFåˆ†æå™¨"""
    
    def __init__(self, structures: List[Structure], rmax: float = 10.0, nbins: int = 100):
        self.structures = structures
        self.rmax = rmax
        self.nbins = nbins
        self.dr = rmax / nbins
        self.r = np.linspace(0, rmax, nbins)
    
    def compute_rdf(self, indices_a: List[int], indices_b: List[int]) -> Tuple[np.ndarray, np.ndarray]:
        """è®¡ç®—æŒ‡å®šåŸå­ç´¢å¼•é—´çš„RDF"""
        rdf_sum = np.zeros(self.nbins)
        
        for structure in self.structures:
            # è·å–åŸå­ä½ç½®
            coords_a = np.array([structure[i].coords for i in indices_a])  # type: ignore
            coords_b = np.array([structure[i].coords for i in indices_b])  # type: ignore
            
            # è®¡ç®—è·ç¦»çŸ©é˜µ
            distances = []
            for coord_a in coords_a:
                for j, coord_b in enumerate(coords_b):
                    if indices_a != indices_b or coord_a is not coord_b:  # é¿å…è‡ªç›¸å…³
                        # ä½¿ç”¨pymatgençš„æœ€çŸ­è·ç¦»è®¡ç®—ï¼ˆè€ƒè™‘å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼‰
                        dist = structure.lattice.get_distance_and_image(coord_a, coord_b)[0]
                        if dist <= self.rmax:
                            distances.append(dist)
            
            # ç»Ÿè®¡ç›´æ–¹å›¾
            hist, _ = np.histogram(distances, bins=self.nbins, range=(0, self.rmax))
            rdf_sum += hist
        
        # å½’ä¸€åŒ–
        n_a = len(indices_a)
        n_b = len(indices_b)
        volume = np.mean([s.lattice.volume for s in self.structures])
        density = n_b / volume
        
        # RDFå½’ä¸€åŒ–ï¼šg(r) = (V/(N_a*N_b)) * (1/(4Ï€rÂ²dr)) * hist
        normalization = np.zeros_like(self.r)
        for i in range(len(self.r)):
            r_val = self.r[i]
            if r_val > 0:
                shell_volume = 4 * np.pi * r_val**2 * self.dr
                normalization[i] = volume / (n_a * shell_volume * len(self.structures))
        
        # é¿å…é™¤é›¶é”™è¯¯
        normalization[0] = 0
        rdf_sum[0] = 0
        
        rdf = rdf_sum * normalization
        return self.r, rdf



# å›¾å½¢/æ—¥å¿—
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# ç‰©ç†å¸¸æ•°
KB_J_PER_K = 1.380649e-23  # J/K
E_CHARGE_C = 1.602176634e-19  # C
ANG3_TO_M3 = 1e-30
PS_TO_S = 1e-12


class VASP_MDAnalyzer:
    """VASP åˆ†å­åŠ¨åŠ›å­¦æ™ºèƒ½åˆ†æå™¨

    å‚è€ƒ `dos_analyzer.py` çš„é¢å‘å¯¹è±¡ç»“æ„ä¸è¾“å‡ºé£æ ¼ã€‚
    """

    def __init__(
        self,
        input_path: str,
        task_id: Optional[str] = None,
        output_dir: Optional[str] = None,
        mobile_species: Optional[List[str]] = None,
        rdf_rmax: float = 10.0,
        rdf_bin_width: float = 0.1,
        rdf_stride: int = 5,
    ) -> None:
        """åˆå§‹åŒ–

        Args:
            input_path: å•æ¬¡MDç›®å½•ï¼Œæˆ–åŒ…å«å¤šæ¸©åº¦å­ç›®å½•çš„ä¸Šçº§ç›®å½•
            task_id: ä»»åŠ¡ID
            output_dir: è¾“å‡ºç›®å½•ï¼›é»˜è®¤ <work_dir>/MD_output
            mobile_species: å¾…è¯„ä¼°ç”µå¯¼ç‡çš„è¿ç§»ç¦»å­ï¼ˆé»˜è®¤è‡ªåŠ¨è¯†åˆ« Li/Na/K/Mg...ï¼‰
            rdf_rmax: RDF æˆªæ­¢åŠå¾„ (Ã…)
            rdf_bin_width: RDF ç›´æ–¹å›¾ bin å®½åº¦ (Ã…)
            rdf_stride: RDF é‡‡æ ·æ­¥é•¿ï¼ˆé™ä½è®¡ç®—é‡ï¼‰
        """
        self.input_path = Path(input_path)
        self.task_id = task_id or 'md_analysis'
        self.work_dir = self.input_path
        self.output_dir = Path(output_dir) if output_dir else self.work_dir / 'MD_output'
        self.output_dir.mkdir(exist_ok=True)

        # è¿è¡Œå†…çŠ¶æ€
        self.mobile_species = mobile_species
        self.rdf_rmax = float(rdf_rmax)
        self.rdf_bin_width = float(rdf_bin_width)
        self.rdf_stride = int(max(1, rdf_stride))

        # æ–‡ä»¶è·¯å¾„
        self.xdatcar_path = self.work_dir / 'XDATCAR'
        self.outcar_path = self.work_dir / 'OUTCAR'
        self.vasprun_path = self.work_dir / 'vasprun.xml'
        self.incar_path = self.work_dir / 'INCAR'

        # æ•°æ®å®¹å™¨
        self.structures: List[Structure] = []
        self.lattice_volumes: List[float] = []
        self.time_step_ps: Optional[float] = None
        self.temperature_K: Optional[float] = None
        self.temperature_series: List[float] = []
        self.pressure_series: List[float] = []
        self.energy_series: List[float] = []
        self.lattice_series: Dict[str, List[float]] = {'a': [], 'b': [], 'c': [], 'vol': []}

        self.analysis_data: Dict[str, Any] = {}

    # =============================
    # ä¸»å…¥å£
    # =============================
    def analyze(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´MDåˆ†æï¼ˆå•æ¸©åº¦ç›®å½•ï¼‰ï¼›è‹¥ç›®å½•å†…å«å­ç›®å½•ï¼Œåˆ™è‡ªåŠ¨å°è¯•åš Arrhenius èšåˆã€‚

        Returns:
            Dict[str, Any]: åˆ†ææ•°æ®æ±‡æ€»
        """
        logger.info(f"ğŸš€ å¼€å§‹ VASP MD åˆ†æ: {self.work_dir}")

        try:
            # æ£€æµ‹æ˜¯å¦å¤šè¿è¡Œï¼ˆç”¨äºArrheniusï¼‰
            md_subdirs = self._discover_md_subdirs(self.work_dir)
            if md_subdirs:
                logger.info(f"æ£€æµ‹åˆ° {len(md_subdirs)} ä¸ªå­è¿è¡Œï¼Œæ‰§è¡Œ Arrhenius èšåˆåˆ†æâ€¦")
                arrh = self._analyze_arrhenius_across_subdirs(md_subdirs)
                self.analysis_data['arrhenius'] = arrh

            # å•è¿è¡Œå¸¸è§„åˆ†æ
            self._load_md_data()
            if not self.structures:
                raise FileNotFoundError('æœªèƒ½åŠ è½½MDç»“æ„æ•°æ®ï¼ˆXDATCARï¼‰')

            self._analyze_stability()
            diffusion = self._analyze_diffusion()
            self.analysis_data['diffusion'] = diffusion

            rdf = self._analyze_rdf()
            self.analysis_data['rdf'] = rdf

            self._generate_visualizations()
            self._generate_markdown_report()

            # HTML æŠ¥å‘Š
            html_path = self._generate_html_report()
            self.analysis_data['report_html'] = html_path

            logger.info('âœ… VASP MD åˆ†æå®Œæˆ')
            return self.analysis_data

        except Exception as e:
            logger.error(f"âŒ MD åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

    # =============================
    # æ•°æ®åŠ è½½ä¸é€šç”¨å·¥å…·
    # =============================
    def _discover_md_subdirs(self, root: Path) -> List[Path]:
        """æ‰«æ root ä¸‹çš„å­ç›®å½•ï¼Œè‹¥å­˜åœ¨ XDATCAR åˆ™è®¤ä¸ºæ˜¯ä¸€ä¸ªç‹¬ç«‹MDè¿è¡Œã€‚

        ä»…ç”¨äº Arrhenius èšåˆï¼Œä¸å½±å“å½“å‰ç›®å½•åˆ†æã€‚
        """
        subdirs: List[Path] = []
        try:
            for p in root.iterdir():
                if p.is_dir() and (p / 'XDATCAR').exists():
                    subdirs.append(p)
        except Exception:
            pass
        return subdirs

    def _load_md_data(self) -> None:
        """åŠ è½½ XDATCAR è½¨è¿¹ä¸ OUTCAR/INCAR/vasprun çš„è¾…åŠ©ä¿¡æ¯"""
        logger.info('ğŸ“¦ åŠ è½½MDæ•°æ®â€¦')

        # 1) XDATCAR
        if not self.xdatcar_path.exists():
            raise FileNotFoundError(f'æœªæ‰¾åˆ° XDATCAR: {self.xdatcar_path}')
        xdatcar = Xdatcar(str(self.xdatcar_path))
        self.structures = xdatcar.structures
        logger.info(f'åŠ è½½ç»“æ„å¸§æ•°: {len(self.structures)}')

        # 2) é‡‡æ ·æ™¶æ ¼å‚æ•°
        self.lattice_volumes = [float(s.lattice.volume) for s in self.structures]
        self.lattice_series['a'] = [float(s.lattice.a) for s in self.structures]
        self.lattice_series['b'] = [float(s.lattice.b) for s in self.structures]
        self.lattice_series['c'] = [float(s.lattice.c) for s in self.structures]
        self.lattice_series['vol'] = self.lattice_volumes

        # 3) INCAR: POTIM ä¼°ç®—æ—¶é—´æ­¥é•¿ï¼ˆfsâ†’psï¼‰
        if self.incar_path.exists():
            try:
                incar = Incar.from_file(str(self.incar_path))
                potim = float(incar.get('POTIM', 1.0))  # fs
                self.time_step_fs = potim
                self.time_step_ps = potim * 1e-3
                logger.info(f'æ—¶é—´æ­¥é•¿ POTIM = {potim} fs ({self.time_step_ps:.6f} ps)')
            except Exception as e:
                logger.warning(f'è¯»å– INCAR å¤±è´¥: {e}')
        # 4) vasprun.xml è¡¥å……ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.vasprun_path.exists():
            try:
                v = Vasprun(str(self.vasprun_path), exception_on_bad_xml=False)
                if self.time_step_ps is None:
                    # æœ‰äº›ç‰ˆæœ¬æä¾› ionic_step_timeï¼ˆfsï¼‰æˆ–æ—¶åºï¼Œå¯å›é€€ä¼°ç®—
                    try:
                        ts_fs = float(getattr(v, 'ionic_step_time', None) or 1.0)
                        self.time_step_fs = ts_fs
                        self.time_step_ps = ts_fs * 1e-3
                    except Exception:
                        pass
                # ä¼°è®¡æ¸©åº¦ï¼ˆè‹¥æ˜¯æ’æ¸©å™¨MDï¼Œå¯è¯»å– TEBEG/TEENDï¼›æ­¤å¤„ä¼˜å…ˆ OUTCARï¼‰
            except Exception as e:
                logger.warning(f'è¯»å– vasprun.xml å¤±è´¥: {e}')

        # 5) OUTCAR: æ¸©åº¦ã€å‹åŠ›ã€èƒ½é‡éšæ—¶é—´
        if self.outcar_path.exists():
            try:
                outcar = Outcar(str(self.outcar_path))
                # å°è¯•æ¨¡å¼åŒ¹é…æ¸©åº¦/å‹åŠ›/èƒ½é‡
                # æ¸©åº¦æ¨¡å¼ - å°è¯•å¤šç§å¯èƒ½çš„æ ¼å¼
                temp_patterns = [
                    r"temperature\s+([0-9\.]+)\s+K",      # temperature 300.0 K
                    # r"TEBEG\s*=\s*([0-9\.]+)",            # TEBEG = 300.0 (ä»INCARéƒ¨åˆ†)
                    # r"T=\s*([0-9\.]+)",                   # T= 300.0
                    # r"TEMP\s*=\s*([0-9\.]+)",             # TEMP = 300.0
                ]
                
                temps = []
                for pattern in temp_patterns:
                    try_temps = self._read_outcar_pattern(outcar, pattern)
                    if try_temps:
                        temps = try_temps
                        logger.info(f"ä½¿ç”¨æ¸©åº¦æ¨¡å¼: {pattern}")
                        break
                
                if temps:
                    self.temperature_series = [float(t[0]) for t in temps]
                    # å¹³å‡æ¸©åº¦
                    self.temperature_K = float(np.mean(self.temperature_series)) if self.temperature_series else None
                else:
                    self.temperature_K = None

                # å‹åŠ›ï¼ˆkBï¼‰æˆ– barï¼ŒVASP OUTCAR å¸¸è§è¡Œï¼š"external pressure =   xxx kB"
                pressure_patterns = [
                    r"external\s+pressure\s*=\s*(-?[\d\.\-]+)\s*kB",    # external pressure = -0.12 kB
                    r"pressure\s*=\s*(-?[\d\.\-]+)",                    # pressure = -0.12
                    r"PRESS\s*=\s*(-?[\d\.\-]+)",                       # PRESS = -0.12
                ]
                
                pressures = []
                for pattern in pressure_patterns:
                    try_pressures = self._read_outcar_pattern(outcar, pattern)
                    if try_pressures:
                        pressures = try_pressures
                        logger.info(f"ä½¿ç”¨å‹åŠ›æ¨¡å¼: {pattern}")
                        break
                
                if pressures:
                    self.pressure_series = [float(p[0]) for p in pressures]

                # èƒ½é‡ TOTENï¼ˆeVï¼‰- ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å®é™…OUTCARæ ¼å¼
                print("outcar",outcar)
                # å°è¯•å¤šç§èƒ½é‡æ¨¡å¼
                energy_patterns = [
                    # r"energy\s+without\s+entropy\s*=\s*(-?[0-9\.\-]+)",  # energy without entropy = -189.32447661
                    # r"energy\(sigma->0\)\s*=\s*(-?[0-9\.\-]+)",          # energy(sigma->0) = -189.32688170  
                    r"free\s+energy\s+TOTEN\s*=\s*(-?[0-9\.\-]+)",       # free energy TOTEN = xxx
                    # r"TOTEN\s*=\s*(-?[0-9\.\-]+)",                       # TOTEN = xxx
                ]
                
                energies = []
                for pattern in energy_patterns:
                    try_energies = self._read_outcar_pattern(outcar, pattern)

                    if try_energies:
                        energies = try_energies
                        logger.info(f"ä½¿ç”¨èƒ½é‡æ¨¡å¼: {pattern}")
                        break
                
                if energies:
                    energy_values = [float(e[0]) for e in energies]
                    # åªå–ä¸ç»“æ„å¸§æ•°ç›¸åŒçš„èƒ½é‡ç‚¹ï¼ˆæ¯ä¸ªMDæ­¥çš„æœ€åä¸€ä¸ªèƒ½é‡ï¼‰
                    n_structures = len(self.structures)
                    if len(energy_values) > n_structures:
                        # æ¯nä¸ªç‚¹å–æœ€åä¸€ä¸ªï¼Œæˆ–è€…ç®€å•åœ°æŒ‰æ­¥é•¿é‡‡æ ·
                        stride = len(energy_values) // n_structures
                        self.energy_series = energy_values[stride-1::stride][:n_structures]
                        logger.info(f"èƒ½é‡æ•°æ®é™é‡‡æ ·: {len(energy_values)} -> {len(self.energy_series)} ç‚¹")
                    else:
                        self.energy_series = energy_values

                logger.info(
                    f"OUTCAR ç»Ÿè®¡: æ¸©åº¦ç‚¹={len(self.temperature_series)}, å‹åŠ›ç‚¹={len(self.pressure_series)}, èƒ½é‡ç‚¹={len(self.energy_series)}"
                )
            except Exception as e:
                logger.warning(f'è§£æ OUTCAR å¤±è´¥: {e}')

        # é»˜è®¤æ—¶é—´æ­¥é•¿å…œåº•
        if self.time_step_ps is None:
            self.time_step_ps = 1.0  # 1 ps å…œåº•ï¼Œé¿å…ä¸º None
            logger.warning('æœªèƒ½ä» INCAR/vasprun è·å–æ—¶é—´æ­¥é•¿ï¼Œä½¿ç”¨é»˜è®¤ 1.0 ps')

        # é»˜è®¤æ¸©åº¦å…œåº•
        if self.temperature_K is None:
            # è‹¥æ— ç³»åˆ—ï¼Œå°è¯• INCAR çš„ TEBEG
            try:
                if self.incar_path.exists():
                    incar = Incar.from_file(str(self.incar_path))
                    self.temperature_K = float(incar.get('TEBEG', 300))
            except Exception:
                self.temperature_K = 300.0
            logger.warning(f'æœªèƒ½ä» OUTCAR æå–æ¸©åº¦ï¼Œä½¿ç”¨ {self.temperature_K} K')

        # è‡ªåŠ¨è¯†åˆ«è¿ç§»ç¦»å­
        if not self.mobile_species:
            self.mobile_species = self._auto_mobile_species(self.structures[0])
            logger.info(f"è‡ªåŠ¨è¯†åˆ«è¿ç§»ç¦»å­: {', '.join(self.mobile_species) if self.mobile_species else 'æ— '}")

    def _read_outcar_pattern(self, outcar: Outcar, regex: str) -> List[List[str]]:
        """ç›´æ¥ä»OUTCARæ–‡ä»¶è¯»å–å¹¶ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…"""
        import re
        try:
            with open(self.outcar_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            pattern = re.compile(regex)
            matches = pattern.findall(content)
            # å°†åŒ¹é…ç»“æœè½¬æ¢ä¸ºList[List[str]]æ ¼å¼
            if matches:
                return [[match] if isinstance(match, str) else list(match) for match in matches]
            return []
        except Exception as e:
            logger.warning(f"è¯»å–OUTCARæ¨¡å¼åŒ¹é…å¤±è´¥: {e}")
            return []

    def _auto_mobile_species(self, structure: Structure) -> List[str]:
        """æ ¹æ®ç»„æˆè‡ªåŠ¨æ¨æ–­å¯èƒ½çš„è¿ç§»ç¦»å­ï¼ˆä¼˜å…ˆ Li/Na/K/Mg/Ag/Hï¼‰"""
        candidates = ['Li', 'Na', 'K', 'Mg', 'Ag', 'H']
        present = set([str(el) for el in structure.composition.elements])
        return [s for s in candidates if s in present]

    # =============================
    # æ‰©æ•£æ€§è´¨åˆ†æ
    # =============================
    def _analyze_diffusion(self) -> Dict[str, Any]:
        logger.info('ğŸ“ˆ æ‰©æ•£æ€§è´¨åˆ†æï¼ˆMSD/æ‰©æ•£ç³»æ•°/ç”µå¯¼ç‡/Arrheniusï¼‰â€¦')
        # å…œåº•ç¡®ä¿é None
        time_step_ps_val = float(self.time_step_ps if self.time_step_ps is not None else 1.0)

        time_step_s = time_step_ps_val * PS_TO_S

        # MSD æŒ‰å…ƒç´ 
        msd_by_elem = self._compute_msd_by_element(time_step_s=time_step_s)

        # ä½¿ç”¨ DiffusionAnalyzer ç›´æ¥è®¡ç®—æ‰©æ•£ç³»æ•°å’Œç”µå¯¼ç‡
        diffusion_by_elem: Dict[str, Dict[str, float]] = {}
        conductivity: Dict[str, float] = {}
        
        structures = self.structures
        species_labels = [site.species_string for site in structures[0]]
        unique_elements = sorted(set(species_labels))
        print("time_step_fs",self.time_step_fs)

        for elem in unique_elements:
            try:
                tempK = float(self.temperature_K or 300.0)
                da = DiffusionAnalyzer.from_structures( # type: ignore
                    structures,
                    specie=elem,
                    temperature=tempK,
                    time_step=self.time_step_fs,
                    step_skip=1,
                    smoothed=False,
                )
                
                # ç›´æ¥ä» DiffusionAnalyzer è·å–æ‰©æ•£ç³»æ•°
                D_cm2_per_s = da.diffusivity  # cmÂ²/s
                D_m2_per_s = float(D_cm2_per_s * 1e-4)  # è½¬æ¢ä¸º mÂ²/s
                # è·å–æ‹Ÿåˆä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                fit_slope = getattr(da, 'slope', 0.0)
                fit_intercept = getattr(da, 'intercept', 0.0) 
                fit_r2 = getattr(da, 'r2', 0.0)
                
                diffusion_by_elem[elem] = {
                    'D_m2_per_s': D_m2_per_s,
                    'D_cm2_per_s': float(D_cm2_per_s),
                    'fit_slope': float(fit_slope),
                    'fit_intercept': float(fit_intercept),
                    'fit_r2': float(fit_r2)
                }
                
                # è®¡ç®—ç”µå¯¼ç‡ï¼ˆä»…å¯¹è¿ç§»ç¦»å­ï¼‰
                if self.mobile_species and elem in self.mobile_species:
                    try:
                        # ä½¿ç”¨ DiffusionAnalyzer çš„å†…ç½®ç”µå¯¼ç‡è®¡ç®—
                        if hasattr(da, 'conductivity'):
                            sigma_S_per_cm = da.conductivity  # S/cm
                            conductivity[elem] = float(sigma_S_per_cm * 100)  # è½¬æ¢ä¸º S/m
                            print("sigma_S_per_cm",sigma_S_per_cm)
                        else:
                            # æ‰‹å·¥è®¡ç®— Nernst-Einstein ç”µå¯¼ç‡
                            avg_vol_m3 = float(np.mean(self.lattice_volumes)) * ANG3_TO_M3
                            comp = self.structures[0].composition
                            n_species = comp[Element(elem)]  # åŸèƒä¸­åŸå­æ•°
                            number_density = (n_species / avg_vol_m3)  # 1/m^3
                            z = self._guess_charge_number(elem)
                            sigma = number_density * (z * E_CHARGE_C) ** 2 * D_m2_per_s / (KB_J_PER_K * tempK)
                            conductivity[elem] = float(sigma)
                    except Exception as e:
                        logger.warning(f"è®¡ç®—å…ƒç´  {elem} ç”µå¯¼ç‡å¤±è´¥: {e}")
                        
            except Exception as e:
                logger.warning(f"DiffusionAnalyzer åˆ†æå…ƒç´  {elem} å¤±è´¥: {e}")
                # å›é€€åˆ°æ‰‹å·¥MSDæ–¹æ³•
                if elem in msd_by_elem:
                    times = msd_by_elem[elem]['time_s']
                    values = msd_by_elem[elem]['msd']
                    slope, intercept, r2 = self._fit_linear_tail(times, values)
                    # Einstein relation: <r^2> = 2*d*D*tï¼ˆ3Dï¼‰
                    D = max(slope / (2 * 3), 0.0)
                    diffusion_by_elem[elem] = {
                        'D_m2_per_s': float(D),
                        'D_cm2_per_s': float(D * 1e4),
                        'fit_slope': float(slope),
                        'fit_intercept': float(intercept),
                        'fit_r2': float(r2)
                    }
                    print(elem,diffusion_by_elem[elem])
        # Arrheniusï¼ˆè‹¥å•ç›®å½•ï¼Œä»…è¿”å›å½“å‰ç‚¹ï¼›å¤šç›®å½•åˆ†æç”± _analyze_arrhenius_across_subdirs æä¾›ï¼‰
        arrhenius = {
            'T_list_K': [float(self.temperature_K or 300.0)],
            'D_list_m2_per_s': [float(np.mean([v['D_m2_per_s'] for v in diffusion_by_elem.values()]) if diffusion_by_elem else 0.0)]
        }

        # å¯¼å‡º CSV/JSON
        self._save_msd_results(msd_by_elem, diffusion_by_elem, conductivity)

        return {
            'msd_by_element': msd_by_elem,
            'diffusion_by_element': diffusion_by_elem,
            'ionic_conductivity_S_per_m': conductivity,
            'arrhenius_single': arrhenius
        }

    def _compute_msd_by_element(self, time_step_s: float) -> Dict[str, Dict[str, np.ndarray]]:
        """æŒ‰å…ƒç´ è®¡ç®— MSDï¼ˆä¼˜å…ˆä½¿ç”¨ PyMatGen DiffusionAnalyzerï¼›å¦åˆ™æ‰‹å·¥PBCè§£ç¼ +ç´¯ç§¯ï¼‰ã€‚"""
        structures = self.structures
        if len(structures) < 2:
            return {}

        species_labels = [site.species_string for site in structures[0]]
        unique_elements = sorted(set(species_labels))

        # ä¼˜å…ˆä½¿ç”¨ DiffusionAnalyzerï¼ˆå¦‚å¯ç”¨ï¼‰
        if DiffusionAnalyzer is not None:
            try:
                tempK = float(self.temperature_K or 300.0)
                msd_by_elem_da: Dict[str, Dict[str, np.ndarray]] = {}
                for elem in unique_elements:
                    try:
                        print("DiffusionAnalyzer is available")
                        print("elem", elem)
                        da = DiffusionAnalyzer.from_structures(
                            structures,
                            specie=elem,
                            temperature=tempK,
                            time_step=time_step_s,
                            step_skip=1,
                            smoothed=False,
                        )
                        times_arr = None
                        msd_arr = None
                        if hasattr(da, 'msd') and getattr(da, 'msd') is not None:
                            msd_raw = np.array(getattr(da, 'msd'))
                            if msd_raw.ndim == 1:
                                msd_arr = msd_raw
                            else:
                                # è‹¥ä¸º (n, 3/4) ç­‰å¤šåˆ—ï¼Œå–å„å‘å¹³å‡
                                msd_arr = np.mean(msd_raw, axis=1)
                            dt_val = float(getattr(da, 'dt', time_step_s))
                            times_arr = np.arange(len(msd_arr), dtype=float) * dt_val
                        if times_arr is not None and msd_arr is not None:
                            msd_by_elem_da[elem] = {'time_s': np.array(times_arr), 'msd': np.array(msd_arr)}
                    except Exception:
                        continue
                if msd_by_elem_da:
                    return msd_by_elem_da
            except Exception as e:
                logger.warning(f'DiffusionAnalyzer ä¸å¯ç”¨æˆ–å‘ç”Ÿé”™è¯¯ï¼Œä½¿ç”¨æ‰‹å·¥MSD: {e}')

        # æ‰‹å·¥ï¼šåŸºäºPBCæœ€çŸ­åƒè§£ç¼ ï¼Œç´¯è®¡ä½ç§»
        frac_0 = np.array([site.frac_coords for site in structures[0]])
        num_atoms = frac_0.shape[0]
        cum_disp_cart = np.zeros((num_atoms, 3), dtype=float)

        # æ—¶é—´åºåˆ—
        times = np.arange(len(structures), dtype=float) * time_step_s
        msd_all_frames = []  # (frame, per-atom |r|^2)

        prev_frac = frac_0
        for k in range(1, len(structures)):
            s_prev = structures[k - 1]
            s_curr = structures[k]
            frac_curr = np.array([site.frac_coords for site in s_curr])
            df = frac_curr - prev_frac
            df -= np.round(df)  # unwrap to [-0.5, 0.5]
            # ä½¿ç”¨ä¸Šä¸€å¸§æ™¶æ ¼å°†åˆ†æ•°ä½ç§»å˜æ¢åˆ°ç¬›å¡å°”
            dcart = s_prev.lattice.get_cartesian_coords(df)
            cum_disp_cart += dcart
            # ç›¸å¯¹åˆæ€ä½ç§»çš„å¹³æ–¹
            msd_all_frames.append(np.sum(cum_disp_cart ** 2, axis=1))
            prev_frac = frac_curr

        # æ±‡æ€»åˆ°å…ƒç´ 
        msd_by_elem: Dict[str, Dict[str, np.ndarray]] = {}
        msd_all_frames_arr = np.array(msd_all_frames)  # shape (n-1, N)
        times_eff = times[1:]

        for elem in unique_elements:
            mask = np.array([sp == elem for sp in species_labels])
            if not np.any(mask):
                continue
            msd_elem = np.mean(msd_all_frames_arr[:, mask], axis=1)
            msd_by_elem[elem] = {
                'time_s': times_eff,
                'msd': msd_elem
            }

        return msd_by_elem

    def _fit_linear_tail(self, x: np.ndarray, y: np.ndarray, start_frac: float = 0.2, end_frac: float = 0.8) -> Tuple[float, float, float]:
        """å¯¹å°¾æ®µè¿›è¡Œçº¿æ€§æ‹Ÿåˆï¼Œè¿”å› slope/intercept/R^2ã€‚"""
        if len(x) < 5 or len(y) < 5:
            return 0.0, 0.0, 0.0
        n = len(x)
        i0 = int(max(0, math.floor(n * start_frac)))
        i1 = int(min(n, math.ceil(n * end_frac)))
        if i1 - i0 < 3:
            i0 = 0
            i1 = n
        xx = x[i0:i1]
        yy = y[i0:i1]
        A = np.vstack([xx, np.ones_like(xx)]).T
        slope, intercept = np.linalg.lstsq(A, yy, rcond=None)[0]
        # R^2
        yhat = slope * xx + intercept
        ss_res = float(np.sum((yy - yhat) ** 2))
        ss_tot = float(np.sum((yy - np.mean(yy)) ** 2)) + 1e-20
        r2 = 1.0 - ss_res / ss_tot
        return float(slope), float(intercept), float(r2)

    def _guess_charge_number(self, elem: str) -> int:
        """åŸºäºå¸¸è§ä»·æ€çŒœæµ‹ç”µè·æ•° |z|ï¼ˆä»…ç”¨äºä¼°ç®—ç”µå¯¼ç‡ï¼‰"""
        mapping = {
            'Li': 1, 'Na': 1, 'K': 1, 'Ag': 1,
            'Mg': 2, 'Ca': 2, 'Al': 3,
            'H': 1
        }
        return mapping.get(elem, 1)

    def _save_msd_results(
        self,
        msd_by_elem: Dict[str, Dict[str, np.ndarray]],
        diffusion_by_elem: Dict[str, Dict[str, float]],
        conductivity: Dict[str, float],
    ) -> None:
        data_dir = self.output_dir / 'data'
        data_dir.mkdir(exist_ok=True)
        # MSD CSV
        for elem, data in msd_by_elem.items():
            df = pd.DataFrame({'time_s': data['time_s'], 'msd_m2': data['msd']})
            df.to_csv(data_dir / f'MSD_{elem}.csv', index=False)
        # æ‰©æ•£ & ç”µå¯¼ç‡ JSON
        results = {
            'diffusion_by_element': diffusion_by_elem,
            'ionic_conductivity_S_per_m': conductivity,
            'temperature_K': float(self.temperature_K or 300.0),
            'mobile_species': self.mobile_species or [],
            'analysis_method': 'DiffusionAnalyzer + Manual_fallback',
            'units': {
                'diffusivity': 'mÂ²/s and cmÂ²/s',
                'conductivity': 'S/m',
                'temperature': 'K'
            }
        }
        with open(data_dir / 'diffusion_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

    # =============================
    # RDF åˆ†æ
    # =============================
    def _analyze_rdf(self) -> Dict[str, Any]:
        logger.info('ğŸ” RDF/é…ä½/å³°ä½/ç»“æ„æ¼”åŒ–åˆ†æï¼ˆåŸºäºPyMatGenï¼‰â€¦')
        if not self.structures:
            return {}

        # ä¼˜å…ˆä½¿ç”¨pymatgençš„RadialDistributionFunction
        if RadialDistributionFunction is not None:
            logger.info('ä½¿ç”¨ PyMatGen RadialDistributionFunction è¿›è¡ŒRDFåˆ†æ')
            return self._analyze_rdf_pymatgen()
        else:
            logger.info('ä½¿ç”¨è‡ªå®šä¹‰ PyMatGen RDF åˆ†æå™¨ï¼ˆåŸºäºpymatgenæ ¸å¿ƒåŠŸèƒ½ï¼‰')
            return self._analyze_rdf_pymatgen_custom()

    def _analyze_rdf_pymatgen(self) -> Dict[str, Any]:
        """ä½¿ç”¨pymatgençš„RadialDistributionFunctionè¿›è¡ŒRDFåˆ†æ"""
        structures = self.structures[:: self.rdf_stride]
        ngrid = int(self.rdf_rmax / self.rdf_bin_width)
        
        # è·å–æ‰€æœ‰å…ƒç´ 
        species = [str(el) for el in structures[0].composition.elements]
        logger.info(f'æ£€æµ‹åˆ°çš„å…ƒç´ : {species}')
        
        # ç”Ÿæˆæ‰€æœ‰å…ƒç´ å¯¹
        pairs: List[Tuple[str, str]] = []
        for i, a in enumerate(species):
            for j, b in enumerate(species):
                if j < i:
                    continue
                pairs.append((a, b))
        
        g_pairs: Dict[str, Dict[str, Any]] = {}
        r_array = None
        
        for a, b in pairs:
            try:
                # è·å–åŸå­ç´¢å¼•
                indices_a = self._get_species_indices(structures[0], a)
                indices_b = self._get_species_indices(structures[0], b)
                
                if not indices_a or not indices_b:
                    logger.warning(f'å…ƒç´ å¯¹ {a}-{b} ç´¢å¼•ä¸ºç©ºï¼Œè·³è¿‡')
                    continue
                
                # ä½¿ç”¨pymatgençš„RadialDistributionFunction
                rdf_analyzer = RadialDistributionFunction(  # type: ignore
                    structures=structures,
                    indices=indices_a,
                    reference_indices=indices_b,
                    rmax=self.rdf_rmax,
                    ngrid=ngrid,
                    sigma=0.1  # é«˜æ–¯å¹³æ»‘å‚æ•°
                )
                
                # æå–ç»“æœ - ä½¿ç”¨æ­£ç¡®çš„å±æ€§å
                r_array = rdf_analyzer.interval  # rè½´æ•°ç»„
                g_rdf = rdf_analyzer.rdf  # g(r)æ•°ç»„
                
                # åˆ†æå³°ä½å’Œé…ä½æ•°
                peaks, mins, cn = self._analyze_rdf_features(r_array, g_rdf, structures[0], a, b)
                
                g_pairs[f'{a}-{b}'] = {
                    'g_r': g_rdf,
                    'peaks': peaks,
                    'mins': mins,
                    'coordination_number': cn,
                    'method': 'pymatgen_RadialDistributionFunction'
                }
                
                logger.info(f'âœ… {a}-{b} RDF åˆ†æå®Œæˆ (CN={cn:.2f})')
                
            except Exception as e:
                logger.warning(f'å…ƒç´ å¯¹ {a}-{b} RDF åˆ†æå¤±è´¥: {e}')
                continue
        
        # æ€»RDFï¼ˆæ‰€æœ‰åŸå­å¯¹çš„å¹³å‡ï¼‰
        if r_array is not None and g_pairs:
            g_all = np.mean([val['g_r'] for val in g_pairs.values()], axis=0)
        else:
            # å›é€€åˆ°æ‰‹å·¥è®¡ç®—
            logger.warning('PyMatGen RDFåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°æ‰‹å·¥è®¡ç®—')
            return self._analyze_rdf_manual()
        
        # ç»“æ„æ¼”åŒ–åˆ†æ
        evolution = self._track_first_peak_evolution_pymatgen(structures, species[0] if species else 'all')
        
        # ä¿å­˜æ•°æ®
        self._save_rdf_results(r_array, g_all, g_pairs)
        
        return {
            'r_A': r_array,
            'g_all': g_all,
            'g_pairs': g_pairs,
            'evolution': evolution,
            'method': 'pymatgen'
        }

    def _analyze_rdf_pymatgen_custom(self) -> Dict[str, Any]:
        """ä½¿ç”¨è‡ªå®šä¹‰PyMatGen RDFåˆ†æå™¨"""
        structures = self.structures[:: self.rdf_stride]
        nbins = int(self.rdf_rmax / self.rdf_bin_width)
        
        # åˆ›å»ºè‡ªå®šä¹‰RDFåˆ†æå™¨
        rdf_analyzer = PyMatGenRDFAnalyzer(structures, rmax=self.rdf_rmax, nbins=nbins)
        
        # è·å–æ‰€æœ‰å…ƒç´ 
        species = [str(el) for el in structures[0].composition.elements]
        logger.info(f'æ£€æµ‹åˆ°çš„å…ƒç´ : {species}')
        
        # ç”Ÿæˆæ‰€æœ‰å…ƒç´ å¯¹
        pairs: List[Tuple[str, str]] = []
        for i, a in enumerate(species):
            for j, b in enumerate(species):
                if j < i:
                    continue
                pairs.append((a, b))
        
        g_pairs: Dict[str, Dict[str, Any]] = {}
        r_array = None
        
        for a, b in pairs:
            try:
                # è·å–åŸå­ç´¢å¼•
                indices_a = self._get_species_indices(structures[0], a)
                indices_b = self._get_species_indices(structures[0], b)
                
                if not indices_a or not indices_b:
                    logger.warning(f'å…ƒç´ å¯¹ {a}-{b} ç´¢å¼•ä¸ºç©ºï¼Œè·³è¿‡')
                    continue
                
                # ä½¿ç”¨è‡ªå®šä¹‰RDFåˆ†æå™¨
                r_array, g_rdf = rdf_analyzer.compute_rdf(indices_a, indices_b)
                
                # åˆ†æå³°ä½å’Œé…ä½æ•°
                peaks, mins, cn = self._analyze_rdf_features(r_array, g_rdf, structures[0], a, b)
                
                g_pairs[f'{a}-{b}'] = {
                    'g_r': g_rdf,
                    'peaks': peaks,
                    'mins': mins,
                    'coordination_number': cn,
                    'method': 'pymatgen_custom_rdf'
                }
                
                logger.info(f'âœ… {a}-{b} RDF åˆ†æå®Œæˆ (CN={cn:.2f})')
                
            except Exception as e:
                logger.warning(f'å…ƒç´ å¯¹ {a}-{b} RDF åˆ†æå¤±è´¥: {e}')
                continue
        
        # æ€»RDFï¼ˆæ‰€æœ‰åŸå­å¯¹çš„å¹³å‡ï¼‰
        if r_array is not None and g_pairs:
            g_all = np.mean([val['g_r'] for val in g_pairs.values()], axis=0)
        else:
            # å›é€€åˆ°æ‰‹å·¥è®¡ç®—
            logger.warning('è‡ªå®šä¹‰ PyMatGen RDFåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°æ‰‹å·¥è®¡ç®—')
            return self._analyze_rdf_manual()
        
        # ç»“æ„æ¼”åŒ–åˆ†æ
        evolution = self._track_first_peak_evolution_custom(structures, species[0] if species else 'all', rdf_analyzer)
        
        # ä¿å­˜æ•°æ®
        self._save_rdf_results(r_array, g_all, g_pairs)
        
        return {
            'r_A': r_array,
            'g_all': g_all,
            'g_pairs': g_pairs,
            'evolution': evolution,
            'method': 'pymatgen_custom'
        }

    def _track_first_peak_evolution_custom(self, structures: List[Structure], reference_species: str, 
                                         rdf_analyzer: PyMatGenRDFAnalyzer) -> Dict[str, Any]:
        """ä½¿ç”¨è‡ªå®šä¹‰RDFåˆ†æå™¨è¿½è¸ªé¦–å³°æ¼”åŒ–"""
        if not structures:
            return {}
        
        first_peak_rs: List[float] = []
        
        # è·å–å‚è€ƒå…ƒç´ çš„ç´¢å¼•
        ref_indices = self._get_species_indices(structures[0], reference_species)
        all_indices = list(range(len(structures[0])))
        
        if not ref_indices:
            return {}
        
        # åˆ›å»ºå•å¸§RDFåˆ†æå™¨
        for i in range(0, len(structures), max(1, len(structures) // 50)):  # é‡‡æ ·50ä¸ªç‚¹
            try:
                single_rdf = PyMatGenRDFAnalyzer([structures[i]], rmax=self.rdf_rmax, nbins=rdf_analyzer.nbins)
                r, g = single_rdf.compute_rdf(ref_indices, all_indices)
                
                # æ‰¾åˆ°é¦–å³°
                if len(g) > 1:
                    max_idx = np.argmax(g[1:]) + 1  # è·³è¿‡r=0ç‚¹
                    first_peak_rs.append(float(r[max_idx]))
                else:
                    first_peak_rs.append(0.0)
                    
            except Exception:
                # å¦‚æœå•å¸§åˆ†æå¤±è´¥
                if first_peak_rs:
                    first_peak_rs.append(first_peak_rs[-1])  # å¤åˆ¶ä¸Šä¸€ä¸ªå€¼
                else:
                    first_peak_rs.append(0.0)
        
        return {
            'first_peak_r_series_A': first_peak_rs,
            'stride': max(1, len(structures) // 50),
            'reference_species': reference_species
        }

    def _analyze_rdf_manual(self) -> Dict[str, Any]:
        """æ‰‹å·¥RDFè®¡ç®—ï¼ˆåŸæœ‰å®ç°ï¼‰"""
        structures = self.structures[:: self.rdf_stride]
        r_edges = np.arange(0.0, self.rdf_rmax + self.rdf_bin_width, self.rdf_bin_width)
        r_centers = 0.5 * (r_edges[:-1] + r_edges[1:])

        # æ‰€æœ‰åŸå­ RDF
        g_all = self._compute_rdf_all(structures, r_edges)

        # æŒ‰å…ƒç´ å¯¹ï¼ˆÎ±Î²ï¼‰
        species = [str(el) for el in structures[0].composition.elements]
        pairs: List[Tuple[str, str]] = []
        for i, a in enumerate(species):
            for j, b in enumerate(species):
                if j < i:
                    continue
                pairs.append((a, b))

        g_pairs: Dict[str, Dict[str, Any]] = {}
        for a, b in pairs:
            g = self._compute_rdf_pair(structures, r_edges, a, b)
            peaks, mins, cn = self._analyze_rdf_features(r_centers, g, structures[0], a, b)
            g_pairs[f'{a}-{b}'] = {
                'g_r': g,
                'peaks': peaks,
                'mins': mins,
                'coordination_number': cn,
                'method': 'manual_calculation'
            }

        # ç»“æ„æ¼”åŒ–ï¼šé¦–å³°ä½ç½®éšæ—¶é—´
        evolution = self._track_first_peak_evolution(structures)

        # ä¿å­˜æ•°æ®
        self._save_rdf_results(r_centers, g_all, g_pairs)

        return {
            'r_A': r_centers,
            'g_all': g_all,
            'g_pairs': g_pairs,
            'evolution': evolution,
            'method': 'manual'
        }

    def _get_species_indices(self, structure: Structure, species: str) -> List[int]:
        """è·å–æŒ‡å®šå…ƒç´ çš„åŸå­ç´¢å¼•"""
        indices = []
        for i, site in enumerate(structure):
            if str(site.specie) == species:
                indices.append(i)
        return indices

    def _track_first_peak_evolution_pymatgen(self, structures: List[Structure], reference_species: str) -> Dict[str, Any]:
        """ä½¿ç”¨pymatgenè¿½è¸ªé¦–å³°æ¼”åŒ–"""
        if not structures or RadialDistributionFunction is None:
            return {}
        
        first_peak_rs: List[float] = []
        ngrid = int(self.rdf_rmax / self.rdf_bin_width)
        
        # è·å–å‚è€ƒå…ƒç´ çš„ç´¢å¼•
        ref_indices = self._get_species_indices(structures[0], reference_species)
        if not ref_indices:
            return {}
        
        for i in range(0, len(structures), max(1, len(structures) // 50)):  # é‡‡æ ·50ä¸ªç‚¹
            try:
                # å•å¸§RDFåˆ†æ
                rdf_analyzer = RadialDistributionFunction(  # type: ignore
                    structures=[structures[i]],
                    indices=ref_indices,
                    reference_indices=list(range(len(structures[i]))),  # ä¸æ‰€æœ‰åŸå­çš„RDF
                    rmax=self.rdf_rmax,
                    ngrid=ngrid,
                    sigma=0.1
                )
                
                # æ‰¾åˆ°é¦–å³° - ä½¿ç”¨æ­£ç¡®çš„å±æ€§å
                r = rdf_analyzer.interval  # rè½´æ•°ç»„
                g = rdf_analyzer.rdf  # g(r)æ•°ç»„
                
                # ç®€å•å³°æ£€æµ‹
                max_idx = np.argmax(g[1:]) + 1  # è·³è¿‡r=0ç‚¹
                first_peak_rs.append(float(r[max_idx]))
                
            except Exception:
                # å¦‚æœå•å¸§åˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ‰‹å·¥æ–¹æ³•
                if first_peak_rs:
                    first_peak_rs.append(first_peak_rs[-1])  # å¤åˆ¶ä¸Šä¸€ä¸ªå€¼
                else:
                    first_peak_rs.append(0.0)
        
        return {
            'first_peak_r_series_A': first_peak_rs,
            'stride': max(1, len(structures) // 50),
            'reference_species': reference_species
        }

    def _save_rdf_results(self, r_array: np.ndarray, g_all: np.ndarray, g_pairs: Dict[str, Dict[str, Any]]) -> None:
        """ä¿å­˜RDFç»“æœ"""
        data_dir = self.output_dir / 'data'
        data_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ€»RDF
        pd.DataFrame({'r_A': r_array, 'g_all': g_all}).to_csv(data_dir / 'RDF_all.csv', index=False)
        
        # ä¿å­˜å„å…ƒç´ å¯¹RDF
        for key, val in g_pairs.items():
            df = pd.DataFrame({'r_A': r_array, 'g': val['g_r']})
            df.to_csv(data_dir / f'RDF_{key}.csv', index=False)
        
        # ä¿å­˜RDFåˆ†ææ±‡æ€»
        rdf_summary = {
            'analysis_method': g_pairs[list(g_pairs.keys())[0]]['method'] if g_pairs else 'unknown',
            'rmax_A': float(self.rdf_rmax),
            'bin_width_A': float(self.rdf_bin_width),
            'stride': self.rdf_stride,
            'pairs_analyzed': list(g_pairs.keys()),
            'coordination_numbers': {k: v['coordination_number'] for k, v in g_pairs.items()},
            'peak_positions': {k: [p['r'] for p in v['peaks'][:3]] for k, v in g_pairs.items()}  # å‰3ä¸ªå³°
        }
        
        with open(data_dir / 'rdf_summary.json', 'w', encoding='utf-8') as f:
            json.dump(rdf_summary, f, indent=2, ensure_ascii=False)

    def _compute_rdf_all(self, structures: List[Structure], r_edges: np.ndarray) -> np.ndarray:
        counts = np.zeros(len(r_edges) - 1, dtype=float)
        n_frames = len(structures)
        s0 = structures[0]
        N = len(s0)
        V = float(np.mean([s.lattice.volume for s in structures]))
        rho = N / V

        for s in structures:
            # åˆ©ç”¨è·ç¦»çŸ©é˜µï¼ˆæœ€çŸ­åƒï¼‰
            dm = s.distance_matrix
            # åªå–ä¸Šä¸‰è§’ i<j
            iu = np.triu_indices(N, k=1)
            dists = dm[iu]
            hist, _ = np.histogram(dists, bins=r_edges)
            counts += hist

        # å½’ä¸€åŒ–: g(r) = V / (N(N-1)) / (4Ï€ r^2 dr) * counts
        r_centers = 0.5 * (r_edges[:-1] + r_edges[1:])
        shell_vol = 4.0 * math.pi * (r_centers ** 2) * np.diff(r_edges)
        norm = (V / (N * (N - 1))) / shell_vol
        g = counts * norm / n_frames
        return g

    def _compute_rdf_pair(self, structures: List[Structure], r_edges: np.ndarray, a: str, b: str) -> np.ndarray:
        counts = np.zeros(len(r_edges) - 1, dtype=float)
        n_frames = len(structures)
        s0 = structures[0]
        species_labels = [site.species_string for site in s0]
        idx_a = [i for i, sp in enumerate(species_labels) if sp == a]
        idx_b = [i for i, sp in enumerate(species_labels) if sp == b]
        N_a = len(idx_a)
        N_b = len(idx_b)
        if N_a == 0 or N_b == 0:
            return np.zeros(len(r_edges) - 1)

        V = float(np.mean([s.lattice.volume for s in structures]))

        for s in structures:
            dm = s.distance_matrix
            # å– a-b å¯¹ï¼ˆè‹¥ a==bï¼Œé¿å…é‡å¤/è‡ªå¯¹ï¼‰
            if a == b:
                iu = np.triu_indices(N_a, k=1)
                dists = dm[np.ix_(idx_a, idx_b)][iu]
            else:
                dists = dm[np.ix_(idx_a, idx_b)].ravel()
            hist, _ = np.histogram(dists, bins=r_edges)
            counts += hist

        r_centers = 0.5 * (r_edges[:-1] + r_edges[1:])
        shell_vol = 4.0 * math.pi * (r_centers ** 2) * np.diff(r_edges)
        # g_ab(r) = V/(N_a N_b) / shell * countsï¼›è‹¥ a==b ç”¨ N_a (N_a-1)
        denom = (N_a * (N_b - 1)) if a == b else (N_a * N_b)
        denom = max(denom, 1)
        norm = (V / denom) / shell_vol
        g = counts * norm / n_frames
        return g

    def _analyze_rdf_features(
        self,
        r_centers: np.ndarray,
        g: np.ndarray,
        structure: Structure,
        a: Optional[str] = None,
        b: Optional[str] = None,
    ) -> Tuple[List[Dict[str, float]], List[Dict[str, float]], float]:
        """å³°ä½/æå°å€¼/é…ä½æ•°ï¼ˆè‡³é¦–æå°å€¼ï¼‰"""
        if len(g) < 5:
            return [], [], 0.0

        # å¹³æ»‘ï¼ˆç®€å•ç§»åŠ¨å¹³å‡ï¼‰
        k = 3
        g_pad = np.pad(g, (k, k), mode='edge')
        g_smooth = np.convolve(g_pad, np.ones(2 * k + 1) / (2 * k + 1), mode='valid')

        peaks = []
        mins = []
        for i in range(1, len(g_smooth) - 1):
            if g_smooth[i] > g_smooth[i - 1] and g_smooth[i] > g_smooth[i + 1] and g_smooth[i] > 1.05:
                peaks.append({'r': float(r_centers[i]), 'g': float(g_smooth[i])})
            if g_smooth[i] < g_smooth[i - 1] and g_smooth[i] < g_smooth[i + 1]:
                mins.append({'r': float(r_centers[i]), 'g': float(g_smooth[i])})

        # æ‰¾é¦–å³°ä¸å…¶åçš„é¦–æå°
        cn = 0.0
        if peaks:
            first_peak_r = peaks[0]['r']
            r_min = None
            for m in mins:
                if m['r'] > first_peak_r:
                    r_min = m['r']
                    break
            if r_min is None:
                r_min = float(r_centers[-1])
            # é…ä½æ•° CN = 4Ï€ âˆ« g_ab(r) r^2 Ï_b dr
            comp = structure.composition
            V = float(structure.lattice.volume)
            rho_b = 0.0
            if b is not None:
                try:
                    N_b = comp[Element(b)]
                    rho_b = N_b / V
                except Exception:
                    rho_b = len(structure) / V
            else:
                rho_b = len(structure) / V

            mask = r_centers <= r_min
            dr = np.gradient(r_centers)
            cn = float(np.trapz(4.0 * math.pi * rho_b * g[mask] * (r_centers[mask] ** 2), x=r_centers[mask]))

        return peaks[:5], mins[:5], float(cn)

    def _track_first_peak_evolution(self, structures: List[Structure]) -> Dict[str, Any]:
        r_edges = np.arange(0.0, self.rdf_rmax + self.rdf_bin_width, self.rdf_bin_width)
        r_centers = 0.5 * (r_edges[:-1] + r_edges[1:])
        first_peak_rs: List[float] = []
        for s in structures:
            g = self._compute_rdf_all([s], r_edges)  # å•å¸§è¿‘ä¼¼
            # ç®€æ˜“å³°æ£€æµ‹
            idx = np.argmax(g)
            first_peak_rs.append(float(r_centers[idx]))
        return {
            'first_peak_r_series_A': first_peak_rs,
            'stride': self.rdf_stride
        }

    # =============================
    # ç¨³å®šæ€§ç›‘æ§
    # =============================
    def _analyze_stability(self) -> None:
        logger.info('ğŸ›¡ï¸ ç³»ç»Ÿç¨³å®šæ€§ç›‘æ§â€¦')
        time_step_ps_val = float(self.time_step_ps if self.time_step_ps is not None else 1.0)
        time_step_s = time_step_ps_val * PS_TO_S
        n_frames = len(self.structures)
        times = np.arange(n_frames, dtype=float) * time_step_s

        # å¯†åº¦ï¼ˆkg/m^3ï¼‰
        mass_list: List[float] = []
        for site in self.structures[0]:
            am = getattr(site.specie, 'atomic_mass', None)
            try:
                mass_list.append(float(am) if am is not None else 0.0)
            except Exception:
                mass_list.append(0.0)
        mass_amu = float(sum(mass_list))
        # 1 amu = 1.66053906660e-27 kg
        mass_kg = mass_amu * 1.66053906660e-27
        vols_m3 = np.array(self.lattice_volumes) * ANG3_TO_M3
        density_series = mass_kg / vols_m3

        # å¹³è¡¡è¯†åˆ«ï¼šèƒ½é‡/æ¸©åº¦æ»šåŠ¨æ–œç‡é˜ˆå€¼
        eq_idx_energy = self._detect_equilibrium_index(times[: len(self.energy_series)], np.array(self.energy_series)) if self.energy_series else None
        eq_idx_temp = self._detect_equilibrium_index(times[: len(self.temperature_series)], np.array(self.temperature_series)) if self.temperature_series else None

        # å¼‚å¸¸é¢„è­¦ï¼šZåˆ†æ•°
        anomalies = {
            'energy': self._detect_anomaly(np.array(self.energy_series)),
            'temperature': self._detect_anomaly(np.array(self.temperature_series)),
            'pressure': self._detect_anomaly(np.array(self.pressure_series)),
        }

        self.analysis_data['stability'] = {
            'times_s': times.tolist(),
            'energy_eV': self.energy_series,
            'temperature_K': self.temperature_series,
            'pressure_kB': self.pressure_series,
            'lattice': self.lattice_series,
            'density_kg_per_m3': density_series.tolist(),
            'equilibrium_index_energy': int(eq_idx_energy) if eq_idx_energy is not None else None,
            'equilibrium_index_temperature': int(eq_idx_temp) if eq_idx_temp is not None else None,
            'anomalies': anomalies
        }

        # ä¿å­˜æ—¶é—´åºåˆ— CSV
        data_dir = self.output_dir / 'data'
        data_dir.mkdir(exist_ok=True)
        df = pd.DataFrame({
            'time_s': times,
            'energy_eV': self.energy_series[: len(times)] if self.energy_series else [np.nan] * len(times),
            'temperature_K': self.temperature_series[: len(times)] if self.temperature_series else [np.nan] * len(times),
            'pressure_kB': self.pressure_series[: len(times)] if self.pressure_series else [np.nan] * len(times),
            'a_A': self.lattice_series['a'][: len(times)],
            'b_A': self.lattice_series['b'][: len(times)],
            'c_A': self.lattice_series['c'][: len(times)],
            'volume_A3': self.lattice_series['vol'][: len(times)],
            'density_kg_m3': density_series[: len(times)]
        })
        df.to_csv(data_dir / 'time_series.csv', index=False)

    def _detect_equilibrium_index(self, t: np.ndarray, y: np.ndarray, window: int = 50, slope_thr: float = 1e-4) -> Optional[int]:
        if len(t) < window + 2:
            return None
        # ç®€æ˜“ï¼šç§»åŠ¨çª—å£çº¿æ€§æ‹Ÿåˆæ–œç‡ç»å¯¹å€¼å°äºé˜ˆå€¼å³è§†ä¸ºå¹³è¡¡
        for i in range(len(t) - window):
            xx = t[i:i + window]
            yy = y[i:i + window]
            A = np.vstack([xx, np.ones_like(xx)]).T
            slope, _ = np.linalg.lstsq(A, yy, rcond=None)[0]
            if abs(slope) < slope_thr:
                return i + window
        return None

    def _detect_anomaly(self, y: np.ndarray, z_thr: float = 3.0) -> List[int]:
        if y is None or len(y) == 0:
            return []
        m = float(np.nanmean(y))
        s = float(np.nanstd(y) + 1e-12)
        z = np.abs((y - m) / s)
        return [int(i) for i in np.where(z > z_thr)[0]]

    # =============================
    # Arrhenius èšåˆï¼ˆå¤šæ¸©åº¦å­ç›®å½•ï¼‰
    # =============================
    def _analyze_arrhenius_across_subdirs(self, subdirs: List[Path]) -> Dict[str, Any]:
        T_list: List[float] = []
        D_list: List[float] = []

        for p in subdirs:
            try:
                sub = VASP_MDAnalyzer(str(p), mobile_species=self.mobile_species, rdf_rmax=self.rdf_rmax, rdf_bin_width=self.rdf_bin_width, rdf_stride=self.rdf_stride)
                sub._load_md_data()
                diff = sub._analyze_diffusion()
                T = float(sub.temperature_K or 300.0)
                D_mean = float(np.mean([v['D_m2_per_s'] for v in diff['diffusion_by_element'].values()])) if diff['diffusion_by_element'] else 0.0
                if D_mean > 0:
                    T_list.append(T)
                    D_list.append(D_mean)
            except Exception as e:
                logger.warning(f'å­ç›®å½• {p} Arrhenius æ•°æ®æ”¶é›†å¤±è´¥: {e}')

        Ea_eV = None
        slope = None
        intercept = None
        r2 = None
        if len(T_list) >= 2:
            x = 1.0 / np.array(T_list)  # 1/K
            y = np.log(np.array(D_list))
            A = np.vstack([x, np.ones_like(x)]).T
            slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]
            yhat = slope * x + intercept
            ss_res = float(np.sum((y - yhat) ** 2))
            ss_tot = float(np.sum((y - np.mean(y)) ** 2)) + 1e-20
            r2 = 1.0 - ss_res / ss_tot
            # D = D0 * exp(-Ea/(kB T)) => ln D = ln D0 - Ea/kB * 1/T
            Ea_J = -slope * KB_J_PER_K
            Ea_eV = float(Ea_J / E_CHARGE_C)

        # ä¿å­˜å›¾ï¼ˆè‹¥æœ‰ï¼‰
        if len(T_list) >= 2:
            fig, ax = plt.subplots(figsize=(8, 6))
            x = 1.0 / np.array(T_list)
            y = np.log(np.array(D_list))
            ax.scatter(x, y, c='k', label='æ•°æ®ç‚¹')
            if slope is not None and intercept is not None:
                xx = np.linspace(x.min(), x.max(), 100)
                ax.plot(xx, slope * xx + intercept, 'r-', label=f'æ‹Ÿåˆ: ln D = a (1/T) + b\nEa={Ea_eV:.3f} eV, R^2={r2:.3f}')
            ax.set_xlabel('1/T (1/K)')
            ax.set_ylabel('ln D (m^2/s)')
            ax.set_title('Arrhenius å›¾')
            ax.grid(True, alpha=0.3)
            ax.legend()
            plt.tight_layout()
            plt.savefig(self.output_dir / 'arrhenius.png', dpi=300, bbox_inches='tight')
            plt.close(fig)

        return {
            'T_list_K': T_list,
            'D_list_m2_per_s': D_list,
            'fit': {
                'slope': float(slope) if slope is not None else None,
                'intercept': float(intercept) if intercept is not None else None,
                'R2': float(r2) if r2 is not None else None,
                'Ea_eV': Ea_eV
            }
        }

    # =============================
    # å¯è§†åŒ–
    # =============================
    def _generate_visualizations(self) -> None:
        logger.info('ğŸ–¼ï¸ ç”Ÿæˆå¯è§†åŒ–å›¾â€¦')
        self._plot_msd()
        self._plot_stability()
        self._plot_rdf()

    def _plot_msd(self) -> None:
        diff = self.analysis_data.get('diffusion', {})
        msd_by_elem = diff.get('msd_by_element', {})
        diffusion_by_elem = diff.get('diffusion_by_element', {})
        if not msd_by_elem:
            return
        fig, ax = plt.subplots(figsize=(10, 6))
        for elem, data in msd_by_elem.items():
            t = np.array(data['time_s'])
            y = np.array(data['msd'])
            ax.plot(t, y, linewidth=2, label=f'{elem}')
            if elem in diffusion_by_elem:
                slope = diffusion_by_elem[elem]['fit_slope']
                intercept = diffusion_by_elem[elem]['fit_intercept']
                ax.plot(t, slope * t + intercept, linestyle='--', alpha=0.6)
        ax.set_xlabel('æ—¶é—´ (s)')
        ax.set_ylabel('MSD (m^2)')
        ax.set_title('æŒ‰å…ƒç´  MSD åŠçº¿æ€§æ‹Ÿåˆ')
        ax.grid(True, alpha=0.3)
        ax.legend()
        plt.tight_layout()
        plt.savefig(self.output_dir / 'msd.png', dpi=300, bbox_inches='tight')
        plt.close(fig)

    def _plot_stability(self) -> None:
        stab = self.analysis_data.get('stability', {})
        if not stab:
            return
        t = np.array(stab.get('times_s', []))
        if len(t) == 0:
            return
        fig, axs = plt.subplots(3, 1, figsize=(12, 10), sharex=True)
        # èƒ½é‡
        e = np.array(stab.get('energy_eV', []))
        axs[0].plot(t[: len(e)], e, 'k-', linewidth=1)
        axs[0].set_ylabel('èƒ½é‡ (eV)')
        axs[0].grid(True, alpha=0.3)
        # æ¸©åº¦
        temp = np.array(stab.get('temperature_K', []))
        axs[1].plot(t[: len(temp)], temp, 'r-', linewidth=1)
        axs[1].set_ylabel('æ¸©åº¦ (K)')
        axs[1].grid(True, alpha=0.3)
        # å‹åŠ›
        p = np.array(stab.get('pressure_kB', []))
        axs[2].plot(t[: len(p)], p, 'b-', linewidth=1)
        axs[2].set_ylabel('å‹åŠ› (kB)')
        axs[2].set_xlabel('æ—¶é—´ (s)')
        axs[2].grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'stability_energy_temp_pressure.png', dpi=300, bbox_inches='tight')
        plt.close(fig)

        # æ™¶æ ¼ä¸å¯†åº¦
        fig, ax = plt.subplots(figsize=(12, 6))
        a = np.array(stab['lattice'].get('a', []))
        b = np.array(stab['lattice'].get('b', []))
        c = np.array(stab['lattice'].get('c', []))
        vol = np.array(stab['lattice'].get('vol', []))
        ax.plot(t[: len(a)], a, label='a (Ã…)')
        ax.plot(t[: len(b)], b, label='b (Ã…)')
        ax.plot(t[: len(c)], c, label='c (Ã…)')
        ax2 = ax.twinx()
        dens = np.array(stab.get('density_kg_per_m3', []))
        ax2.plot(t[: len(dens)], dens, 'k--', alpha=0.6, label='å¯†åº¦ (kg/m^3)')
        ax.set_xlabel('æ—¶é—´ (s)')
        ax.set_ylabel('æ™¶æ ¼å‚æ•° (Ã…)')
        ax2.set_ylabel('å¯†åº¦ (kg/m^3)')
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'lattice_density.png', dpi=300, bbox_inches='tight')
        plt.close(fig)

    def _plot_rdf(self) -> None:
        rdf = self.analysis_data.get('rdf', {})
        if not rdf:
            return
        r = np.array(rdf.get('r_A', []))
        if len(r) == 0:
            return
        # æ€» RDF
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(r, rdf.get('g_all', []), 'k-', linewidth=2, label='æ‰€æœ‰åŸå­')
        ax.set_xlabel('r (Ã…)')
        ax.set_ylabel('g(r)')
        ax.set_title('æ€» RDF')
        ax.grid(True, alpha=0.3)
        ax.legend()
        plt.tight_layout()
        plt.savefig(self.output_dir / 'rdf_all.png', dpi=300, bbox_inches='tight')
        plt.close(fig)

        # åˆ†å…ƒç´ å¯¹ RDFï¼ˆä¿å­˜æ‰€æœ‰å…ƒç´ å¯¹ï¼‰
        g_pairs = rdf.get('g_pairs', {})
        for key, val in g_pairs.items():
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(r, val.get('g_r', []), linewidth=2, label=key)
            # æ ‡æ³¨å³°
            for pk in val.get('peaks', [])[:3]:
                ax.axvline(x=pk['r'], color='r', linestyle='--', alpha=0.5)
            ax.set_xlabel('r (Ã…)')
            ax.set_ylabel('g(r)')
            ax.set_title(f'RDF: {key} (CNâ‰ˆ{val.get("coordination_number", 0):.2f})')
            ax.grid(True, alpha=0.3)
            ax.legend()
            plt.tight_layout()
            plt.savefig(self.output_dir / f'rdf_{key}.png', dpi=300, bbox_inches='tight')
            plt.close(fig)

        # é¦–å³°æ¼”åŒ–
        evo = rdf.get('evolution', {})
        r1 = np.array(evo.get('first_peak_r_series_A', []))
        if len(r1) > 0:
            time_step_ps_val = float(self.time_step_ps if self.time_step_ps is not None else 1.0)
            t = np.arange(len(r1), dtype=float) * time_step_ps_val * PS_TO_S * int(evo.get('stride', 1))
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(t, r1, 'b-', linewidth=1.5)
            ax.set_xlabel('æ—¶é—´ (s)')
            ax.set_ylabel('é¦–å³°ä½ç½® r1 (Ã…)')
            ax.set_title('RDF é¦–å³°ä½ç½®æ¼”åŒ–')
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(self.output_dir / 'rdf_first_peak_evolution.png', dpi=300, bbox_inches='tight')
            plt.close(fig)

    # =============================
    # æŠ¥å‘Š
    # =============================
    def _generate_markdown_report(self) -> None:
        logger.info('ğŸ“ ç”Ÿæˆ Markdown æŠ¥å‘Šâ€¦')
        lines: List[str] = []
        lines.append('# VASP MD åˆ†ææŠ¥å‘Š')
        lines.append('')
        lines.append('## åŸºæœ¬ä¿¡æ¯')
        lines.append(f'- ä»»åŠ¡ID: {self.task_id}')
        lines.append(f'- å¸§æ•°: {len(self.structures)}')
        lines.append(f'- æ—¶é—´æ­¥é•¿: {self.time_step_ps:.6f} ps')
        lines.append(f'- å¹³å‡æ¸©åº¦: {self.temperature_K:.1f} K')
        lines.append('')
        lines.append('## æ‰©æ•£æ€§è´¨ (DiffusionAnalyzer)')
        diff = self.analysis_data.get('diffusion', {})
        for elem, v in (diff.get('diffusion_by_element', {}) or {}).items():
            D_m2 = v.get("D_m2_per_s", 0)
            D_cm2 = v.get("D_cm2_per_s", 0)
            r2 = v.get("fit_r2", 0)
            lines.append(f'- {elem}: D = {D_m2:.3e} mÂ²/s = {D_cm2:.3e} cmÂ²/s (RÂ²={r2:.3f})')
        if diff.get('ionic_conductivity_S_per_m'):
            lines.append('')
            lines.append('### ç¦»å­ç”µå¯¼ç‡ (åŸºäº DiffusionAnalyzer)')
            for elem, sig in diff['ionic_conductivity_S_per_m'].items():
                lines.append(f'- {elem}: Ïƒ = {sig:.3e} S/m')
            mobile_species = diff.get('mobile_species', [])
            if mobile_species:
                lines.append(f'- è¯†åˆ«çš„è¿ç§»ç¦»å­: {", ".join(mobile_species)}')
        lines.append('')
        if 'arrhenius' in self.analysis_data:
            arrh = self.analysis_data['arrhenius']
            fit = arrh.get('fit', {})
            if fit and fit.get('Ea_eV') is not None:
                lines.append(f'- Arrhenius æ‹Ÿåˆæ¿€æ´»èƒ½: {fit["Ea_eV"]:.3f} eV (R^2={fit.get("R2", 0):.3f})')
        lines.append('')
        lines.append('## RDF/é…ä½ (PyMatGenä¼˜åŒ–)')
        rdf = self.analysis_data.get('rdf', {})
        if rdf:
            method = rdf.get('method', 'unknown')
            lines.append(f'- åˆ†ææ–¹æ³•: {method}')
            lines.append(f'- è®¡ç®—èŒƒå›´: 0 - {self.rdf_rmax} Ã…')
            
            # å…ƒç´ å¯¹RDFç»“æœ
            g_pairs = rdf.get('g_pairs', {})
            if g_pairs:
                lines.append('- å…ƒç´ å¯¹ RDF åˆ†æç»“æœ:')
                for pair, data in g_pairs.items():
                    cn = data.get('coordination_number', 0)
                    peaks = data.get('peaks', [])
                    first_peak = peaks[0]['r'] if peaks else 'N/A'
                    lines.append(f'  - {pair}: é…ä½æ•°={cn:.2f}, é¦–å³°ä½ç½®={first_peak} Ã…')
            
            # ç»“æ„æ¼”åŒ–
            evolution = rdf.get('evolution', {})
            if evolution and evolution.get('first_peak_r_series_A'):
                ref_species = evolution.get('reference_species', 'unknown')
                lines.append(f'- é¦–å³°æ¼”åŒ–è¿½è¸ª: {ref_species} åŸå­ï¼ˆ{len(evolution["first_peak_r_series_A"])} ä¸ªæ—¶é—´ç‚¹ï¼‰')
        lines.append('')
        lines.append('## ç¨³å®šæ€§ç›‘æ§')
        stab = self.analysis_data.get('stability', {})
        if stab:
            lines.append(f'- å¹³è¡¡èƒ½é‡ç´¢å¼•: {stab.get("equilibrium_index_energy")}')
            lines.append(f'- å¹³è¡¡æ¸©åº¦ç´¢å¼•: {stab.get("equilibrium_index_temperature")}')
            anom = stab.get('anomalies', {})
            lines.append(f'- å¼‚å¸¸é¢„è­¦: èƒ½é‡{len(anom.get("energy", []))} æ¸©åº¦{len(anom.get("temperature", []))} å‹åŠ›{len(anom.get("pressure", []))}')
        with open(self.output_dir / 'analysis_report.md', 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        logger.info('å·²ç”Ÿæˆ Markdown æŠ¥å‘Š: analysis_report.md')

    def _generate_html_report(self) -> str:
        logger.info('ğŸŒ ç”Ÿæˆ HTML æŠ¥å‘Šâ€¦')
        generator = MDHTMLReportGenerator(self.analysis_data)
        html_path = str(self.output_dir / 'md_analysis_report.html')
        generator.generate_html_report(html_path)
        logger.info(f'HTML æŠ¥å‘Š: {html_path}')
        return html_path


class MDHTMLReportGenerator:
    """MD åˆ†æ HTML æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆé£æ ¼å‚è€ƒ PyMatGenDOSHTMLGeneratorï¼‰"""
    def __init__(self, analysis_data: Dict[str, Any]) -> None:
        self.data = analysis_data

    def generate_html_report(self, output_path: str) -> str:
        html = self._render()
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        return output_path

    def _render(self) -> str:
        charts = self._collect_charts()
        return f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>VASP MD åˆ†ææŠ¥å‘Š</title>
  {self._css()}
  <style>img{{max-width:100%;height:auto;}}</style>
</head>
<body>
  <div class="container">
    {self._header()}
    {self._summary()}
    {self._section_diffusion(charts)}
    {self._section_rdf(charts)}
    {self._section_stability(charts)}
    {self._footer()}
  </div>
  
</body>
</html>
        """

    def _collect_charts(self) -> Dict[str, str]:
        out = {}
        img_files = {
            'msd': 'msd.png',
            'arrhenius': 'arrhenius.png',
            'rdf_all': 'rdf_all.png',
            'rdf_first_peak_evolution': 'rdf_first_peak_evolution.png',
            'stability': 'stability_energy_temp_pressure.png',
            'lattice_density': 'lattice_density.png',
        }
        for k, fn in img_files.items():
            fp = Path(self.data.get('task_info', {}).get('output_dir', ''))
            if not fp:
                fp = Path('.')
            # ä¼˜å…ˆä½¿ç”¨åˆ†æè¾“å‡ºç›®å½•
            # ç”±äºæ­¤ç”Ÿæˆå™¨å¯èƒ½å¹¶ä¸çŸ¥æ™“ output_dirï¼Œå°è¯•å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ MD_output
            try_candidates = []
            if 'task_info' in self.data and 'output_dir' in self.data['task_info']:
                try_candidates.append(Path(self.data['task_info']['output_dir']) / fn)
            if 'report_html' in self.data:
                try_candidates.append(Path(self.data['report_html']).parent / fn)
            try_candidates.append(Path('MD_output') / fn)

            for p in try_candidates:
                if p.exists():
                    with open(p, 'rb') as f:
                        out[k] = base64.b64encode(f.read()).decode()
                    break
        
        # é¢å¤–ï¼šæ”¶é›†æ‰€æœ‰å…ƒç´ å¯¹ RDF å›¾åƒï¼ˆæ–‡ä»¶åå½¢å¦‚ rdf_*.pngï¼‰
        try:
            rdf_imgs = {}
            search_dirs = []
            if 'task_info' in self.data and 'output_dir' in self.data['task_info']:
                search_dirs.append(Path(self.data['task_info']['output_dir']))
            if 'report_html' in self.data:
                search_dirs.append(Path(self.data['report_html']).parent)
            search_dirs.append(Path('MD_output'))

            for d in search_dirs:
                if d and d.exists():
                    for p in d.glob('rdf_*.png'):
                        key = p.stem  # å¦‚ rdf_Li-O
                        if key not in out:
                            with open(p, 'rb') as f:
                                rdf_imgs[key] = base64.b64encode(f.read()).decode()
            # åˆå¹¶åˆ° outï¼ˆä¸è¦†ç›–å·²å­˜åœ¨é”®ï¼‰
            out.update({k: v for k, v in rdf_imgs.items() if k not in out})
        except Exception:
            pass
        return out

    def _css(self) -> str:
        return """
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', 'PingFang SC', 'Microsoft YaHei', sans-serif; background:#f5f7fb; }
  .container { max-width: 1200px; margin: 20px auto; background: #fff; border-radius: 12px; box-shadow: 0 10px 30px rgba(0,0,0,.06); padding: 24px; }
  h1 { margin: 0 0 10px; }
  .subtitle { color: #666; margin-bottom: 20px; }
  .section { border:1px solid #eee; border-radius: 10px; padding: 16px; margin: 16px 0; background: #fafbff; }
  .section h2 { border-left: 4px solid #667eea; padding-left: 10px; color:#333 }
  .grid-2 { display:grid; grid-template-columns: 1fr 1fr; gap: 16px; }
  .grid-3 { display:grid; grid-template-columns: 1fr 1fr 1fr; gap: 16px; }
  table { width:100%; border-collapse: collapse; }
  th, td { padding: 8px 10px; border-bottom: 1px solid #eee; text-align:left; }
  th { background: #667eea; color: #fff; }
  .note { background: #fff7e6; padding: 10px; border-radius: 8px; border-left: 4px solid #faad14; }
  
  /* RDFä¸“ç”¨æ ·å¼ */
  .rdf-table { margin: 10px 0; }
  .rdf-table th { background: #4ECDC4; color: #fff; }
  .rdf-table td { vertical-align: middle; }
  
  /* å…ƒç´ å¯¹é¢œè‰²æ ‡è¯† */
  .color-li { background: linear-gradient(90deg, #ff9a9e 0%, #fecfef 100%); }
  .color-o { background: linear-gradient(90deg, #a8edea 0%, #fed6e3 100%); }
  .color-p { background: linear-gradient(90deg, #ffecd2 0%, #fcb69f 100%); }
  .color-fe { background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; }
  .color-default { background: #f8f9fa; }
  
  .method-tag { 
    background: #e3f2fd; 
    color: #1565c0; 
    padding: 2px 6px; 
    border-radius: 4px; 
    font-size: 0.8em; 
    font-weight: bold;
  }
  
  /* RDFå¡ç‰‡ç½‘æ ¼ */
  .rdf-grid { 
    display: grid; 
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); 
    gap: 16px; 
    margin: 16px 0; 
  }
  
  .rdf-card { 
    border: 1px solid #e0e0e0; 
    border-radius: 8px; 
    overflow: hidden; 
    background: #fff; 
    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    transition: transform 0.2s ease, box-shadow 0.2s ease;
  }
  
  .rdf-card:hover { 
    transform: translateY(-2px); 
    box-shadow: 0 4px 12px rgba(0,0,0,0.15); 
  }
  
  .rdf-card-header { 
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
    color: white; 
    padding: 12px 16px; 
    display: flex; 
    justify-content: space-between; 
    align-items: center; 
  }
  
  .rdf-card-header h5 { 
    margin: 0; 
    font-size: 1.1em; 
    font-weight: bold; 
  }
  
  .cn-badge { 
    background: rgba(255,255,255,0.2); 
    padding: 4px 8px; 
    border-radius: 12px; 
    font-size: 0.9em; 
    font-weight: bold; 
  }
  
  .rdf-card img { 
    width: 100%; 
    height: auto; 
    display: block; 
  }
  
  /* äº¤äº’å¼å›¾è¡¨æ§åˆ¶æŒ‰é’® */
  .chart-controls { 
    text-align: center; 
  }
  
  .btn { 
    background: #667eea; 
    color: white; 
    border: none; 
    padding: 8px 16px; 
    border-radius: 4px; 
    cursor: pointer; 
    margin: 0 4px; 
    transition: background 0.2s ease;
  }
  
  .btn:hover { 
    background: #5a67d8; 
  }
  
  .btn-sm { 
    padding: 6px 12px; 
    font-size: 0.9em; 
  }
  
  /* å“åº”å¼è®¾è®¡ */
  @media (max-width: 768px) {
    .grid-2, .grid-3 { grid-template-columns: 1fr; }
    .rdf-grid { grid-template-columns: 1fr; }
    .container { margin: 10px; padding: 16px; }
  }
</style>
        """

    def _header(self) -> str:
        task = self.data.get('task_info', {})
        return f"""
  <div>
    <h1>ğŸ§ª VASP MD åˆ†ææŠ¥å‘Š</h1>
    <div class="subtitle">ä»»åŠ¡ID: {task.get('task_id', 'unknown')} | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
  </div>
        """

    def _summary(self) -> str:
        stab = self.data.get('stability', {})
        rdf = self.data.get('rdf', {})
        diff = self.data.get('diffusion', {})
        # é€‰å–ä¸€ä¸ªä»£è¡¨æ‰©æ•£ç³»æ•°
        D_mean = 0.0
        if diff.get('diffusion_by_element'):
            D_mean = float(np.mean([v['D_m2_per_s'] for v in diff['diffusion_by_element'].values()]))
        return f"""
  <div class="section">
    <h2>ğŸ“‹ æ‘˜è¦</h2>
    <div class="grid-3">
      <div>
        <table>
          <tr><th>å±æ€§</th><th>å€¼</th></tr>
          <tr><td>å¸§æ•°</td><td>{len(self.data.get('stability', {}).get('lattice', {}).get('a', []))}</td></tr>
          <tr><td>å¹³å‡æ¸©åº¦ (K)</td><td>{self.data.get('diffusion', {}).get('arrhenius_single', {}).get('T_list_K', [0])[0]:.1f}</td></tr>
          <tr><td>å¹³å‡æ‰©æ•£ç³»æ•° (m^2/s)</td><td>{D_mean:.3e}</td></tr>
        </table>
      </div>
      <div>
        <table>
          <tr><th>æ‰©æ•£ (ç¤ºä¾‹)</th><th>å€¼</th></tr>
          {self._diffusion_rows()}
        </table>
      </div>
      <div>
        <table>
          <tr><th>RDF/é…ä½</th><th>ä¿¡æ¯</th></tr>
          <tr><td>RDF åŠå¾„</td><td>{self.data.get('rdf', {}).get('r_A', [0])[-1] if rdf else 'N/A'} Ã…</td></tr>
          <tr><td>é¦–å³°è¿½è¸ªç‚¹æ•°</td><td>{len(self.data.get('rdf', {}).get('evolution', {}).get('first_peak_r_series_A', [])) if rdf else 0}</td></tr>
        </table>
      </div>
    </div>
  </div>
        """

    def _diffusion_rows(self) -> str:
        diff = self.data.get('diffusion', {})
        rows = []
        if not diff or not diff.get('diffusion_by_element'):
            return ''
        for elem, v in diff['diffusion_by_element'].items():
            rows.append(f"<tr><td>{elem}</td><td>{v['D_m2_per_s']:.3e} m^2/s</td></tr>")
        return '\n'.join(rows[:6])

    def _img(self, img64: str, title: str) -> str:
        if not img64:
            return '<div class="note">æ— å›¾åƒ</div>'
        return f'<img alt="{title}" src="data:image/png;base64,{img64}" />'
    
    def _generate_rdf_table(self, g_pairs: Dict[str, Dict[str, Any]]) -> str:
        """ç”ŸæˆRDFé…ä½æ•°æ±‡æ€»è¡¨æ ¼"""
        if not g_pairs:
            return '<div class="note">æ— RDFæ•°æ®</div>'
        
        rows = []
        for pair, data in g_pairs.items():
            cn = data.get('coordination_number', 0)
            peaks = data.get('peaks', [])
            first_peak = f"{peaks[0]['r']:.2f}" if peaks else 'N/A'
            method = data.get('method', 'unknown')
            
            # ä¸ºä¸åŒå…ƒç´ å¯¹æ·»åŠ é¢œè‰²æ ‡è¯†
            color_class = self._get_pair_color_class(pair)
            
            rows.append(f"""
                <tr class="{color_class}">
                    <td><strong>{pair}</strong></td>
                    <td>{cn:.2f}</td>
                    <td>{first_peak} Ã…</td>
                    <td>{len(peaks)}</td>
                    <td><span class="method-tag">{method}</span></td>
                </tr>
            """)
        
        return f"""
        <table class="rdf-table">
            <thead>
                <tr>
                    <th>å…ƒç´ å¯¹</th>
                    <th>é…ä½æ•°</th>
                    <th>é¦–å³°ä½ç½®</th>
                    <th>å³°æ•°é‡</th>
                    <th>åˆ†ææ–¹æ³•</th>
                </tr>
            </thead>
            <tbody>
                {''.join(rows)}
            </tbody>
        </table>
        """
    
    def _get_pair_color_class(self, pair: str) -> str:
        """ä¸ºä¸åŒå…ƒç´ å¯¹åˆ†é…é¢œè‰²ç±»"""
        color_map = {
            'Li': 'color-li',
            'O': 'color-o', 
            'P': 'color-p',
            'Fe': 'color-fe'
        }
        
        elements = pair.split('-')
        if len(elements) == 2:
            elem1, elem2 = elements
            if elem1 == elem2:
                return color_map.get(elem1, 'color-default')
            else:
                # æ··åˆå…ƒç´ å¯¹ä½¿ç”¨æ¸å˜è‰²
                return f"color-pair-{elem1.lower()}-{elem2.lower()}"
        return 'color-default'
    
    def _generate_rdf_pair_images(self, charts: Dict[str, str], g_pairs: Dict[str, Dict[str, Any]]) -> str:
        """ç”Ÿæˆå…ƒç´ å¯¹RDFå›¾åƒç½‘æ ¼"""
        if not g_pairs:
            return '<div class="note">æ— å…ƒç´ å¯¹RDFå›¾åƒ</div>'
        
        # æŒ‰å…ƒç´ ç±»å‹åˆ†ç»„æ˜¾ç¤º
        pair_groups = self._group_pairs_by_type(g_pairs.keys())
        
        html_parts = []
        for group_name, pairs in pair_groups.items():
            if not pairs:
                continue
                
            html_parts.append(f'<h4>{group_name}</h4>')
            html_parts.append('<div class="rdf-grid">')
            
            for pair in pairs:
                chart_key = f'rdf_{pair}'
                img64 = charts.get(chart_key, '')
                cn = g_pairs[pair].get('coordination_number', 0)
                
                html_parts.append(f'''
                    <div class="rdf-card">
                        <div class="rdf-card-header">
                            <h5>{pair}</h5>
                            <span class="cn-badge">CN: {cn:.2f}</span>
                        </div>
                        {self._img(img64, f'rdf_{pair}')}
                    </div>
                ''')
            
            html_parts.append('</div>')
        
        return ''.join(html_parts)
    
    def _group_pairs_by_type(self, pairs: Iterable[str]) -> Dict[str, List[str]]:
        """æŒ‰å…ƒç´ ç±»å‹å¯¹å…ƒç´ å¯¹åˆ†ç»„"""
        groups = {
            'åŒå…ƒç´ å¯¹': [],
            'é”‚ç›¸å…³': [],
            'æ°§ç›¸å…³': [], 
            'ç£·ç›¸å…³': [],
            'é“ç›¸å…³': [],
            'å…¶ä»–': []
        }
        
        for pair in pairs:
            elements = pair.split('-')
            if len(elements) == 2:
                elem1, elem2 = elements
                if elem1 == elem2:
                    groups['åŒå…ƒç´ å¯¹'].append(pair)
                elif 'Li' in elements:
                    groups['é”‚ç›¸å…³'].append(pair)
                elif 'O' in elements:
                    groups['æ°§ç›¸å…³'].append(pair)
                elif 'P' in elements:
                    groups['ç£·ç›¸å…³'].append(pair)
                elif 'Fe' in elements:
                    groups['é“ç›¸å…³'].append(pair)
                else:
                    groups['å…¶ä»–'].append(pair)
        
        # ç§»é™¤ç©ºç»„
        return {k: v for k, v in groups.items() if v}
    
    def _generate_interactive_rdf_chart(self, r_array: List[float], g_pairs: Dict[str, Dict[str, Any]]) -> str:
        """ç”Ÿæˆäº¤äº’å¼RDFå¯¹æ¯”å›¾è¡¨ï¼ˆä½¿ç”¨Chart.jsï¼‰"""
        if len(r_array) == 0 or not g_pairs:
            return ""
        
        # å‡†å¤‡æ•°æ®
        datasets = []
        colors = ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0', '#9966FF', '#FF9F40', '#FF6384', '#C9CBCF']
        
        for i, (pair, data) in enumerate(g_pairs.items()):
            g_r = data.get('g_r', [])
            if len(g_r) != len(r_array):
                continue
                
            color = colors[i % len(colors)]
            datasets.append({
                'label': pair,
                'data': [{'x': float(r), 'y': float(g)} for r, g in zip(r_array, g_r)],
                'borderColor': color,
                'backgroundColor': color + '20',  # 20% é€æ˜åº¦
                'borderWidth': 2,
                'fill': False,
                'pointRadius': 0,
                'pointHoverRadius': 4
            })
        
        chart_data = {
            'datasets': datasets
        }
        
        return f"""
        <div style="margin: 20px 0;">
            <h3>äº¤äº’å¼RDFå¯¹æ¯”å›¾</h3>
            <div style="position: relative; height: 400px; width: 100%;">
                <canvas id="rdfChart"></canvas>
            </div>
            <div class="chart-controls" style="margin-top: 10px;">
                <button onclick="toggleAllSeries()" class="btn btn-sm">æ˜¾ç¤º/éšè—å…¨éƒ¨</button>
                <button onclick="resetZoom()" class="btn btn-sm">é‡ç½®ç¼©æ”¾</button>
            </div>
        </div>
        
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <script>
            const chartData = {json.dumps(chart_data)};
            const ctx = document.getElementById('rdfChart').getContext('2d');
            
            const rdfChart = new Chart(ctx, {{
                type: 'line',
                data: chartData,
                options: {{
                    responsive: true,
                    maintainAspectRatio: false,
                    interaction: {{
                        intersect: false,
                        mode: 'index'
                    }},
                    plugins: {{
                        legend: {{
                            position: 'top',
                            onClick: function(e, legendItem) {{
                                const index = legendItem.datasetIndex;
                                const chart = this.chart;
                                const meta = chart.getDatasetMeta(index);
                                meta.hidden = meta.hidden === null ? !chart.data.datasets[index].hidden : null;
                                chart.update();
                            }}
                        }},
                        title: {{
                            display: true,
                            text: 'å¾„å‘åˆ†å¸ƒå‡½æ•° g(r) å¯¹æ¯”'
                        }},
                        tooltip: {{
                            callbacks: {{
                                title: function(context) {{
                                    return 'r = ' + context[0].parsed.x.toFixed(2) + ' Ã…';
                                }},
                                label: function(context) {{
                                    return context.dataset.label + ': g(r) = ' + context.parsed.y.toFixed(3);
                                }}
                            }}
                        }}
                    }},
                    scales: {{
                        x: {{
                            type: 'linear',
                            position: 'bottom',
                            title: {{
                                display: true,
                                text: 'r (Ã…)'
                            }},
                            min: 0,
                            max: 10
                        }},
                        y: {{
                            title: {{
                                display: true,
                                text: 'g(r)'
                            }},
                            min: 0
                        }}
                    }},
                    elements: {{
                        line: {{
                            tension: 0.1
                        }}
                    }}
                }}
            }});
            
            function toggleAllSeries() {{
                const chart = rdfChart;
                const allHidden = chart.data.datasets.every(dataset => {{
                    const meta = chart.getDatasetMeta(chart.data.datasets.indexOf(dataset));
                    return meta.hidden === true;
                }});
                
                chart.data.datasets.forEach((dataset, index) => {{
                    const meta = chart.getDatasetMeta(index);
                    meta.hidden = !allHidden;
                }});
                chart.update();
            }}
            
            function resetZoom() {{
                rdfChart.resetZoom();
            }}
        </script>
        """

    def _section_diffusion(self, charts: Dict[str, str]) -> str:
        # ç”µå¯¼ç‡è¡¨æ ¼
        diff = self.data.get('diffusion', {})
        conductivity = diff.get('ionic_conductivity_S_per_m', {}) or {}
        cond_rows = ''
        if conductivity:
            cond_rows = '\n'.join([
                f"<tr><td>{elem}</td><td>{val:.3e} S/m</td></tr>" for elem, val in conductivity.items()
            ])
        conductivity_table = f"""
            <div>
              <h3>ç¦»å­ç”µå¯¼ç‡ï¼ˆNernstâ€“Einstein æˆ– DiffusionAnalyzerï¼‰</h3>
              <table>
                <tr><th>å…ƒç´ </th><th>Ïƒ (S/m)</th></tr>
                {cond_rows if cond_rows else '<tr><td colspan=2>æ— æ•°æ®</td></tr>'}
              </table>
            </div>
        """

        return f"""
  <div class="section">
    <h2>ğŸ“ˆ æ‰©æ•£æ€§è´¨</h2>
    <div class="grid-2">
      <div>
        <h3>MSDï¼ˆæŒ‰å…ƒç´ ï¼‰</h3>
        {self._img(charts.get('msd', ''), 'msd')}
      </div>
      <div>
        <h3>Arrheniusï¼ˆå¤šæ¸©èšåˆæ—¶æ˜¾ç¤ºï¼‰</h3>
        {self._img(charts.get('arrhenius', ''), 'arrhenius')}
      </div>
    </div>
    {conductivity_table}
  </div>
        """

    def _section_rdf(self, charts: Dict[str, str]) -> str:
        # è·å–RDFæ•°æ®ç”¨äºäº¤äº’å¼å¯è§†åŒ–
        rdf_data = self.data.get('rdf', {})
        g_pairs = rdf_data.get('g_pairs', {})
        r_array = rdf_data.get('r_A', [])
        
        # ç”Ÿæˆå…ƒç´ å¯¹RDFè¡¨æ ¼
        rdf_table = self._generate_rdf_table(g_pairs)
        
        # ç”Ÿæˆå…ƒç´ å¯¹RDFå›¾è¡¨ç½‘æ ¼
        rdf_pair_images = self._generate_rdf_pair_images(charts, g_pairs)
        
        # äº¤äº’å¼RDFå›¾è¡¨ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        interactive_chart = self._generate_interactive_rdf_chart(r_array, g_pairs) if len(r_array) > 0 and g_pairs else ""
        
        return f"""
  <div class="section">
    <h2>ğŸ”¬ RDF/é…ä½åˆ†æ</h2>
    
    <!-- æ€»è§ˆå›¾ -->
    <div class="grid-2">
      <div>
        <h3>æ€» RDF</h3>
        {self._img(charts.get('rdf_all', ''), 'rdf_all')}
      </div>
      <div>
        <h3>é¦–å³°æ¼”åŒ–</h3>
        {self._img(charts.get('rdf_first_peak_evolution', ''), 'rdf_first_peak_evolution')}
      </div>
    </div>
    
    <!-- é…ä½æ•°æ±‡æ€»è¡¨ -->
    <div style="margin: 20px 0;">
      <h3>é…ä½æ•°ä¸å³°ä½æ±‡æ€»</h3>
      {rdf_table}
    </div>
    
    <!-- äº¤äº’å¼RDFå¯¹æ¯”å›¾ -->
    {interactive_chart}
    
    <!-- å…ƒç´ å¯¹RDFè¯¦ç»†å›¾è¡¨ -->
    <div style="margin: 20px 0;">
      <h3>å…ƒç´ å¯¹RDFè¯¦ç»†åˆ†æ</h3>
      {rdf_pair_images}
    </div>
  </div>
        """

    def _section_stability(self, charts: Dict[str, str]) -> str:
        return f"""
  <div class="section">
    <h2>ğŸ›¡ï¸ ç¨³å®šæ€§ç›‘æ§</h2>
    <div class="grid-2">
      <div>
        <h3>èƒ½é‡/æ¸©åº¦/å‹åŠ›</h3>
        {self._img(charts.get('stability', ''), 'stability')}
      </div>
      <div>
        <h3>æ™¶æ ¼/å¯†åº¦</h3>
        {self._img(charts.get('lattice_density', ''), 'lattice_density')}
      </div>
    </div>
  </div>
        """

    def _footer(self) -> str:
        return f"""
  <div style="text-align:center;color:#888;margin-top:20px;">
    <div>VASP MD åˆ†ææŠ¥å‘Š | ç”Ÿæˆæ—¶é—´ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
  </div>
        """


def generate_md_analysis_report(input_path: str, task_id: Optional[str] = None, output_dir: Optional[str] = None) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´ MD åˆ†æå¹¶ç”Ÿæˆ HTML æŠ¥å‘Šã€‚

    Args:
        input_path: MD è¾“å‡ºç›®å½•ï¼ˆå« XDATCAR/OUTCAR/vasprun.xmlï¼‰æˆ–å…¶ä¸Šçº§ï¼ˆå«å¤šä¸ªå­è¿è¡Œï¼‰
        task_id: ä»»åŠ¡ID
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        HTML æŠ¥å‘Šè·¯å¾„
    """
    analyzer = VASP_MDAnalyzer(input_path, task_id=task_id, output_dir=output_dir)

    # ä»»åŠ¡ä¿¡æ¯ï¼ˆä¾›HTMLæ”¶é›†å›¾åƒè·¯å¾„ï¼‰
    analyzer.analysis_data['task_info'] = {
        'task_id': analyzer.task_id,
        'input_path': str(analyzer.input_path),
        'output_dir': str(analyzer.output_dir),
        'timestamp': datetime.now().isoformat(),
        'analysis_type': 'VASP_MD_Analysis'
    }
    analyzer.analyze()
    return str(analyzer.output_dir / 'md_analysis_report.html')


if __name__ == '__main__':
    # ç®€æ˜“æµ‹è¯•å…¥å£ï¼ˆè¯·æ ¹æ®å®é™…MDæ•°æ®è·¯å¾„è°ƒæ•´ï¼‰
    test_dir = '/Users/ysl/Desktop/Code/MCP_IC_Tool/md_test/25e88a44d8274fad84caf4e6c5561868'
    output_dir = '/Users/ysl/Desktop/Code/MCP_IC_Tool/md_test/25e88a44d8274fad84caf4e6c5561868/output'
    try:
        html = generate_md_analysis_report(test_dir, task_id='md_test')
        print(f'âœ… MD åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {html}')
    except Exception as e:
        print(f'âŒ æµ‹è¯•å¤±è´¥: {e}')
